###############
##### Plotando fronteira de decisão não-linear
###############

import numpy as np
import matplotlib.pyplot as plt
## TODO: Import the usd func directly sinc copied theta will come without np.

theta = [np.array([[ 0.85048032,  0.2037925 ,  0.33966777],
       [ 0.28621941, -0.03876524, -0.6314872 ],
       [-0.08836962,  0.21943017,  1.10533906],
       [ 0.36092131,  0.00624661, -0.06237574],
       [ 1.00483078,  0.44831728,  0.17395936],
       [ 0.17619601, -0.75461753, -0.73336534],
       [ 0.11098338,  0.52385597,  1.17351265],
       [ 0.40117267,  0.88062736, -0.4937694 ],
       [ 1.14026329,  0.70139632, -0.51112108],
       [-0.71068733,  0.01867466, -0.14194428]]), np.array([[-0.3545969 , -0.11939095, -0.23812175,  0.14378408,  0.01344235,
        -0.16785104, -0.21479427,  0.44087881,  0.00644197, -0.14037385,
         0.46284749],
       [ 0.00161897,  0.25969346,  0.27249534, -0.04189381,  0.15342595,
         0.16372501, -0.06771769,  0.24180885,  0.22464377,  0.34956442,
        -0.63740268],
       [ 0.06894525, -0.37107766,  0.20832471, -0.42196976, -0.31902921,
         0.16283924,  0.25538278, -0.26767148,  0.09477167,  0.29563075,
        -0.03445318],
       [ 0.38368516, -0.54359678,  0.04394236, -0.51661114, -0.43389988,
         0.08814205, -0.00972795, -0.01887254,  0.288345  ,  0.05856584,
        -0.37107243],
       [-0.28683617,  0.58742319, -0.14461784, -0.07266106,  0.3772747 ,
         0.18190968,  0.20868895, -0.17018698,  0.14153795,  0.15501956,
         0.45989077],
       [-0.00700999, -0.50710162,  0.26927795,  0.04233156, -0.01462995,
         0.09168741,  0.18748916,  0.03694711, -0.25866033, -0.05460674,
         0.17716972],
       [-0.12393607, -0.6035546 ,  0.01900472,  0.1288304 ,  0.08725635,
        -0.0070004 ,  0.16686068, -0.37353466, -0.24252827, -0.13210969,
        -0.01036331]]), np.array([[-0.14381253,  0.21150621,  0.62302423, -0.88219187,  0.090987  ,
         0.15138367, -0.13109213, -0.23736432]])]


# Plotando fronteira de decisão
x1s = np.linspace(-1,1.5,50)
x2s = np.linspace(-1,1.5,50)
z=np.zeros((len(x1s),len(x2s)))

#y = h(x) = 1/(1+exp(- z))
#z = theta.T * x

def sigmoid(z, derivative=False):
    sig = 1 / (1 + np.exp(-z))
    if derivative:
        return z * (1 - z)
    return sig

def net_z_output(X, W, l, activation_func=sigmoid):
    Z = []
    A = [X.reshape(-1)]  # Ensure it's a flat vector
    AWB = [np.insert(X, 0, 1)]  # Add bias term to input

    for i in range(l - 1):
        z = np.dot(W[i], AWB[i])
        Z.append(z)
        a = activation_func(z)
        A.append(a)
        AWB.append(np.insert(a, 0, 1))  # Add bias for next layer

    return  Z[-1]


for i in range(len(x1s)):
    for j in range(len(x2s)):
        x = np.array([x1s[i], x2s[j]]).reshape(2,-1)
        z[i,j] = net_z_output(x,theta,4)  # saida do modelo antes de aplicar a função sigmoide - substituir aqui teu código
plt.contour(x1s,x2s,z.T,0)
plt.xlabel("x1")
plt.ylabel("x2")
plt.legend(loc=0)
plt.show()