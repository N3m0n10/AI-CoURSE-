###############
##### Plotando fronteira de decisão não-linear
###############

import numpy as np
import matplotlib.pyplot as plt
## TODO: Import the usd func directly sinc copied theta will come without np.

theta = [np.array([[ 1.00140332,  0.36626383,  0.40729377],
       [ 0.49550949,  0.09429952, -0.12237774],
       [ 0.37783207,  0.65494911,  0.7882779 ],
       [ 0.54389097,  0.29011957, -0.5473856 ],
       [ 0.15397889,  0.69392196,  0.41127209],
       [ 0.06035494, -0.66519696,  0.50654165],
       [ 0.49423699, -0.12741175, -0.87251613],
       [ 0.39244874,  0.43323702,  0.90961163],
       [-0.24137896, -0.41103134, -0.96958975],
       [ 0.43267266,  1.1743109 , -0.67053079]]), np.array([[-0.23089127,  0.03056133,  0.37727616, -0.15816711,  0.41760456,
        -0.27427482,  0.5592422 ,  0.02468917, -0.39131796,  0.08557821,
         0.18453434],
       [ 0.16136994, -0.02011556, -0.48680502,  0.21574866, -0.267376  ,
         0.22855058, -0.30207155,  0.01467697, -0.00667121,  0.17302765,
        -0.48181446],
       [ 0.36202831, -0.20958887,  0.5548137 ,  0.11988065, -0.25235042,
        -0.25945605,  0.32944328,  0.17764995, -0.07032352,  0.26371469,
         0.16301464],
       [-0.41760368,  0.12309439,  0.28390104, -0.4002221 ,  0.0712459 ,
        -0.01322873,  0.32223947, -0.24224971,  0.24060657, -0.39191441,
        -0.30123377],
       [ 0.08650602, -0.15952918,  0.21537031, -0.28799834,  0.26963454,
         0.53151562, -0.17658208,  0.07339423,  0.29879111,  0.35402127,
        -0.41807315],
       [-0.75238383,  0.0603723 , -0.08722532, -0.00692508,  0.51494299,
        -0.01959555,  0.52749613, -0.37345675,  0.0712971 ,  0.14453876,
         0.27996066],
       [ 0.02218474,  0.23731499,  0.21987668, -0.22891074,  0.34925741,
         0.05424599, -0.26048777, -0.10724744, -0.21607023, -0.09932175,
         0.47827993]]), np.array([[ 0.90762966,  0.50837564,  0.02165463, -0.4216381 , -0.57095943,
        -0.26328237, -0.3213707 , -0.37278623]])]


# Plotando fronteira de decisão
x1s = np.linspace(-1,1.5,50)
x2s = np.linspace(-1,1.5,50)
z=np.zeros((len(x1s),len(x2s)))

#y = h(x) = 1/(1+exp(- z))
#z = theta.T * x

def sigmoid(z, derivative=False):
    sig = 1 / (1 + np.exp(-z))
    if derivative:
        return z * (1 - z)
    return sig

def net_z_output(X, W, l, activation_func=sigmoid):
    Z = []
    A = [X.reshape(-1)]  # Ensure it's a flat vector
    AWB = [np.insert(X, 0, 1)]  # Add bias term to input

    for i in range(l - 1):
        z = np.dot(W[i], AWB[i])
        Z.append(z)
        a = activation_func(z)
        A.append(a)
        AWB.append(np.insert(a, 0, 1))  # Add bias for next layer

    return  Z[-1]


for i in range(len(x1s)):
    for j in range(len(x2s)):
        x = np.array([x1s[i], x2s[j]]).reshape(2,-1)
        z[i,j] = net_z_output(x,theta,4)  # saida do modelo antes de aplicar a função sigmoide - substituir aqui teu código
plt.contour(x1s,x2s,z.T,0)
plt.xlabel("x1")
plt.ylabel("x2")
plt.legend(loc=0)
plt.show()